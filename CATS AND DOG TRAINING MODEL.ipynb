{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98843608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\msaim\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9624fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2f608a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a861285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0b38617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ee31762",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the CNN(Classifier Neural Network)\n",
    "classifier = Sequential()\n",
    "\n",
    "#STEP 1 CONVOLUTION\n",
    "classifier.add(Conv2D(32, (3,3), input_shape = (64,64,3), activation = 'relu'))\n",
    "\n",
    "#STEP 2 Adding a second convolution layer\n",
    "classifier.add(Conv2D(32, (3,3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b53a3637",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 3:FLATTENING\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#STEP 4 :FULL CONNECTION\n",
    "classifier.add(Dense(units = 28, activation = 'relu'))\n",
    "classifier.add(Dense(units = 1, activation = 'sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61481dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 5: COMPILING THE CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3292d732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART 2- FITTING THE CNN TO THE IMAGES\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fcdd53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('C:/Users/msaim/Downloads/train',\n",
    "                                                 target_size = (64,64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9358e671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = train_datagen.flow_from_directory('C:/Users/msaim/Downloads/test1',\n",
    "                                                 target_size = (64,64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b6e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training the model\n",
    "#classifier.fit_generator is the back propagation,information goes through\n",
    "#forward and then the weights are taken back to confirm t or f\n",
    "#we are using the training set we created above and epochs means we are going through\n",
    "#the set 25 times  processing 25000 pictures\n",
    "#we are using the test_set to validate and we shall validate the output with 12500 images\n",
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 25000,\n",
    "                         epochs = 25,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 12500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a30e0a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msaim\\AppData\\Local\\Temp\\ipykernel_17312\\3815376453.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  classifier.fit_generator(training_set,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 10s 813ms/step - loss: 0.0700 - accuracy: 0.9844 - val_loss: 2.4745e-09 - val_accuracy: 1.0000\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 8s 807ms/step - loss: 9.8811e-10 - accuracy: 1.0000 - val_loss: 2.0690e-14 - val_accuracy: 1.0000\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 7s 717ms/step - loss: 1.2453e-13 - accuracy: 1.0000 - val_loss: 1.7564e-15 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22c266840a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 10,\n",
    "                         epochs = 3,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af5a1133",
   "metadata": {},
   "source": [
    "The code is set  three epochs where 10 images are chosen per epoch for training and 5 images from the test_set dataset will be used for validation.\n",
    "#the 10/10  means that the model is picking 10 pictures each epoch and going through them.\n",
    "the 10s show the time it is taking to go through the 10 pictures(note the time changes for each epoch)\n",
    "#the validation step comes in where we have accuracy,loss, value accuracy and value loss.\n",
    "Accuracy is while it is running, it compares the two numbers............\n",
    "Accuracy and value accuracy are bias values, inthat at some point while the accuracy goes down, the val accuracy goes up.(this means that there is memorizing the dogs and cats but not what makes a dog and what makes a cat a cat.)\n",
    "\n",
    "cat.0.jpg\n",
    "dog.5427.jpg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d0c3709",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf0df1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 174ms/step\n",
      "cat\n"
     ]
    }
   ],
   "source": [
    "#Making new preddiction\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = Image.open('C:/Users/msaim/Downloads/cats_dogs/cat.0.jpg').resize((64, 64))\n",
    "test_image = np.array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "print(prediction)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a400de5",
   "metadata": {},
   "source": [
    "#The above code imports numpy as np and image from keras.processing which allows us to load our querry image that the model has not seen and alter it to target size 64 by 64.\n",
    "we then set the image to an array, and use np to expand our image to an axis of 0 which is a single array.\n",
    "we then run the result in classifier.predict test image.\n",
    "we then create a dictionary of indices of the two sets of images in the training set in this case we have cats and dogs, if in the dictionary cats appear first, and dogs second, when the probability score(0.5) of the input image is lower than 0.5, it is assigned to cat and if it is above, then it is assigned to dog.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e412e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "cat\n"
     ]
    }
   ],
   "source": [
    "#changing result parameters\n",
    "#Unknown image is a cat\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = Image.open('C:/Users/msaim/Downloads/cats_dogs/cat.0.jpg').resize((64, 64))\n",
    "test_image = np.array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 0:\n",
    "    prediction = 'cat'\n",
    "else:\n",
    "    prediction = 'dog'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2a41970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "cat\n"
     ]
    }
   ],
   "source": [
    "#selected an image which is neither a cat or a dog\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = Image.open('C:/Users/msaim/Downloads/cats_dogs/IMGL1439.JPG').resize((64, 64))\n",
    "test_image = np.array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 0:\n",
    "    prediction = 'cat'\n",
    "elif():\n",
    "    result[0][0] == 1\n",
    "    prediction = 'dog'\n",
    "else:    \n",
    "    print(\"image not identified\")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8154ca1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 36ms/step\n",
      "cat\n"
     ]
    }
   ],
   "source": [
    "#selected an image of a dog\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = Image.open('C:/Users/msaim/Downloads/cats_dogs/dog.5427.jpg').resize((64, 64))\n",
    "test_image = np.array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 0:\n",
    "    prediction = 'cat'\n",
    "elif():\n",
    "    result[0][0] == 1\n",
    "    prediction = 'dog'\n",
    "else:    \n",
    "    print(\"image not identified\")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cbf2c972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "cat\n"
     ]
    }
   ],
   "source": [
    "#selected a dog as an image\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = Image.open('C:/Users/msaim/Downloads/cats_dogs/dog.5427.jpg').resize((64, 64))\n",
    "test_image = np.array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] == 0:\n",
    "    prediction = 'cat'\n",
    "else:\n",
    "    prediction = 'dog'\n",
    "print(prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "50bf47ab",
   "metadata": {},
   "source": [
    ">- wondering if the reason the model is returning cat everytime is because the probability of all input images is less than 0.5 thus cannot be seen as dog.\n",
    ">- and this would mean the model didnot get enough training of what a dog is\n",
    ">- requesting for an explanation of how the probability scores are computed and assigned as well as the relationship between the accuracy and value accuracy generated in each echop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2104c403",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
